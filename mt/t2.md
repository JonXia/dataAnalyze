# Datawhale AI夏令营——机器翻译赛道
本次[比赛（machine-translation-2024）](https://challenge.xfyun.cn/topic/info?type=machine-translation-2024&option=tjjg&ch=dw24_AtTCK9)旨在使用术语词典在domain场景优化翻译质量。

数据预处理的常用步骤：

> - **清洗和规范化数据**
>   - **去除无关信息**：删除HTML标签、特殊字符、非文本内容等，确保文本的纯净性（本赛题的训练集中出现了非常多的脏数据，如“Joey.        （掌声） （掌声） 乔伊”、“Thank you.        （马嘶声） 谢谢你们”等这种声音词）
>   - **统一格式**：转换所有文本为小写，确保一致性；标准化日期、数字等格式。
>   - **分句和分段**：将长文本分割成句子或段落，便于处理和训练。
> - **分词**
>   - **分词**：将句子分解成**单词或词素**（构成单词的基本组成部分，一个词素可以是一个完整的单词，也可以是单词的一部分，但每一个词素都至少携带一部分语义或语法信息），这是NLP中最基本的步骤之一。我们这里使用了使用`jieba` 对中文进行分词，使用`spaCy`对英文进行分词。
> - **构建词汇表和词向量**
>   - **词汇表构建**：从训练数据中收集所有出现过的词汇，**构建词汇表，并为每个词分配一个唯一的索引**。
>   - **词向量**：使用预训练的词向量或自己训练词向量，将词汇表中的词映射到高维空间中的向量，以捕捉语义信息（当前大模型领域训练的 embedding 模型就是用来完成此任务的）。
> - **序列截断和填充**
>   - **序列截断**：限制输入序列的长度，过长的序列可能增加计算成本，同时也可能包含冗余信息。
>   - **序列填充**：将所有序列**填充至相同的长度，便于批量处理**。通常使用`<PAD>`标记填充。
> - **添加特殊标记**
>   - **序列开始和结束标记**：在**序列两端**添加`<SOS>`（Sequence Start）和`<EOS>`（Sequence End）标记，帮助模型**识别序列的起始和结束**。
>   - **未知词标记**：为不在词汇表中的词添加`<UNK>`（Unknown）标记，使模型能够**处理未见过的词汇**。
> - **数据增强**
>   - **随机替换或删除词**：在训练数据中随机替换或删除一些词，增强模型的鲁棒性。
>   - **同义词替换**：使用同义词替换原文中的词，增加训练数据的多样性。
> - **数据分割**
>   - **划分数据集**：将数据划分为训练集、验证集和测试集，分别用于模型训练、参数调整和最终性能评估（该赛题中已划分好，不需要自己进行划分）



本次baseline的模型是经典的seq2seq模型框架：

seq2seq的编码器会处理输入序列的每个元素，并转化为context。当我们处理好整个序列后编码器把上下文发送给解码器，解码器逐项生成元素。

在transformer出现之前，一直是以RNN或LSTM为主。你可以在编写seq2seq模型的时候设置上下文向量的长度。这个长度是基于编码器 RNN 的隐藏层神经元的数量。

根据设计，RNN 在每个时间步接受 2 个输入：

- 输入序列中的一个元素（在解码器的例子中，输入是指句子中的一个单词，最终被转化成一个向量(embedding)）
- 一个  hidden state（隐藏层状态，也对应一个向量）

RNN的输出送给解码器，解码器输出响应的文本。

![1-6-seq2seq](pics/t2/1-6-seq2seq.gif)

## 翻译评价：

本次比赛使用的是BLEU-4：

> `BLEU`，全称为`Bilingual Evaluation Understudy`（双语评估替换），是一种对`生成语句`进行`评估的指标`。BLEU 评分是由Kishore Papineni等人2002年的论文[《BLEU: a Method for Automatic Evaluation of Machine Translation》](http://www.aclweb.org/anthology/P02-1040.pdf)中提出的。
>
> 在机器翻译领域，BLEU（Bilingual Evaluation Understudy）是一种常用的自动评价指标，用于衡量**计算机生成的翻译与一组参考译文之间的相似度**。这个指标特别关注 **n-grams**（连续的n个词）的精确匹配，可以被认为是对翻译准确性和流利度的一种统计估计。计算BLEU分数时，首先会统计生成文本中n-grams的频率，然后将这些频率与参考文本中的n-grams进行比较。如果生成的翻译中包含的n-grams与参考译文中出现的相同，则认为是匹配的。最终的BLEU分数是一个介于0到1之间的数值，其中1表示与参考译文完美匹配，而0则表示完全没有匹配。
>
> **BLEU****-4** 特别指的是在计算时考虑四元组（即连续四个词）的匹配情况。
>
> **BLEU** 评估指标的特点：
>
> - 优点：计算速度快、计算成本低、容易理解、与具体语言无关、和人类给的评估高度相关。
> - 缺点：不考虑语言表达（语法）上的准确性；测评精度会受常用词的干扰；短译句的测评精度有时会较高；没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定。
>
> 除了翻译之外，BLEU评分结合深度学习方法可应用于其他的语言生成问题，例如：语言生成、图片标题生成、文本摘要、语音识别。
